<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Deep Learning from Scratch - Training Skills(1)</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->

    <!-- 수식 -->

    
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$'] ],
    processEscapes: true,
  }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

    


    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Deeplearning Archive" />
    <link rel="shortcut icon" href="https://ilvnax24er.github.io/" type="image/png" />
    <link rel="canonical" href="https://ilvnax24er.github.io/Optimization" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Archive" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Deep Learning from Scratch - Training Skills(1)" />
    <meta property="og:description" content="Optimization SGD(Stochastic Gradient Descent) $W \leftarrow W - \eta \frac{\partial L}{\partial W}$ 여기에서 $W$는 갱신할 가중치 매개변수이며, $\frac{\partial L}{\partial W}$은 $W$에 대한 손실 함수의 깅루기이다. $\eta$는 학습률을 의미하는데, 0.01이나 0.001과 같은 값을 미리 정해서 사용한다. import matplotlib.pyplot as plt import numpy as np from matplotlib import cm class SGD: def" />
    <meta property="og:url" content="https://ilvnax24er.github.io/Optimization" />
    <meta property="og:image" content="https://ilvnax24er.github.io/assets/built/images/scratch-cover.png" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta property="article:author" content="https://www.facebook.com/" />
    <meta property="article:published_time" content="2021-08-10T00:00:00+09:00" />
    <meta property="article:modified_time" content="2021-08-10T00:00:00+09:00" />
    <meta property="article:tag" content="Deeplearning" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Deep Learning from Scratch - Training Skills(1)" />
    <meta name="twitter:description" content="Optimization SGD(Stochastic Gradient Descent) $W \leftarrow W - \eta \frac{\partial L}{\partial W}$ 여기에서 $W$는 갱신할 가중치 매개변수이며, $\frac{\partial L}{\partial W}$은 $W$에 대한 손실 함수의 깅루기이다. $\eta$는 학습률을 의미하는데, 0.01이나 0.001과 같은 값을 미리 정해서 사용한다. import matplotlib.pyplot as plt import numpy as np from matplotlib import cm class SGD: def" />
    <meta name="twitter:url" content="https://ilvnax24er.github.io/" />
    <meta name="twitter:image" content="https://ilvnax24er.github.io/assets/built/images/scratch-cover.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Archive" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Deeplearning" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Archive",
        "logo": "https://ilvnax24er.github.io/"
    },
    "url": "https://ilvnax24er.github.io/Optimization",
    "image": {
        "@type": "ImageObject",
        "url": "https://ilvnax24er.github.io/assets/built/images/scratch-cover.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://ilvnax24er.github.io/Optimization"
    },
    "description": "Optimization SGD(Stochastic Gradient Descent) $W \leftarrow W - \eta \frac{\partial L}{\partial W}$ 여기에서 $W$는 갱신할 가중치 매개변수이며, $\frac{\partial L}{\partial W}$은 $W$에 대한 손실 함수의 깅루기이다. $\eta$는 학습률을 의미하는데, 0.01이나 0.001과 같은 값을 미리 정해서 사용한다. import matplotlib.pyplot as plt import numpy as np from matplotlib import cm class SGD: def"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Deep Learning from Scratch - Training Skills(1)" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://ilvnax24er.github.io/">Archive</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-deeplearning" role="menuitem"><a href="/tag/deeplearning/">deeplearning</a></li>
    <li class="nav-pytorch" role="menuitem"><a href="/tag/pytorch/">pytorch</a></li>
    <li class="nav-reinforcement" role="menuitem"><a href="/tag/reinforcement/">reinforcement</a></li>
    <li class="nav-timeseries" role="menuitem"><a href="/tag/timeseries/">timeseries</a></li>
    <li class="nav-exercise" role="menuitem"><a href="/tag/exercise/">exercise</a></li>
    <li class="nav-archive" role="menuitem">
    <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
    <a href="/author_archive.html">Tag별 Posts</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-deeplearning post tag-deeplearning ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="10 August 2021">10 August 2021</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/deeplearning/'>DEEPLEARNING</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Deep Learning from Scratch - Training Skills(1)</h1>
            </header>

            <!-- cover on/off
                        
            <figure class="post-full-image" style="background-image: url(/assets/built/images/scratch-cover.png)">
            </figure>
            
            -->



            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <h1 id="optimization">Optimization</h1>

<h2 id="sgdstochastic-gradient-descent">SGD(Stochastic Gradient Descent)</h2>
<center>$W \leftarrow W - \eta \frac{\partial L}{\partial W}$</center>
<p>여기에서 $W$는 갱신할 가중치 매개변수이며, $\frac{\partial L}{\partial W}$은 $W$에 대한 손실 함수의 깅루기이다. $\eta$는 학습률을 의미하는데, 0.01이나 0.001과 같은 값을 미리 정해서 사용한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SGD</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</code></pre></div></div>

<p>SGD는 단순하고 구현도 쉽지만, 문제에 따라서는 비효율적이다. 비등방성 함수의 경우 탐색 경로가 비효율적이다.</p>
<h2 id="fxy--frac120x2--y2">$f(x,y) = \frac{1}{20}x^{2} + y^{2}$</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fxy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">20</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dfx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dfy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">20</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">initial</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">initial</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">gradient_x</span> <span class="o">=</span> <span class="n">dfx</span><span class="p">(</span><span class="n">initial</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">initial</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">gradient_y</span> <span class="o">=</span> <span class="n">dfx</span><span class="p">(</span><span class="n">initial</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">initial</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">gradient_x</span><span class="p">,</span> <span class="n">gradient_y</span><span class="p">])</span>
    <span class="n">initial</span> <span class="o">=</span> <span class="n">initial</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">gradients</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">answer</span><span class="p">,</span> <span class="n">initial</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">initial</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.0000001</span> <span class="ow">and</span> <span class="n">initial</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.0000001</span><span class="p">:</span>
        <span class="k">break</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">fxy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="p">.</span><span class="n">coolwarm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">answer</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">answer</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">fxy</span><span class="p">(</span><span class="n">answer</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">answer</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]),</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\assets\built\images\post_images\Scratch\optimization\output_9_0.png" alt="png" /></p>

<h2 id="momentum">Momentum</h2>
<center>$\nu \leftarrow \alpha \nu - \eta \frac{\partial L}{\partial W}$</center>
<center>$W \leftarrow W + \nu$</center>

<p>여기서 $\nu$는 속도에 해당한다. 즉 기울기 방향으로 힘을 받아 물체가 가속된다는 물리 법칙을 나타낸다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Momentum</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="adagrad">AdaGrad</h2>
<p>Learning Rate($\eta$)의 값이 너무 작으면 학습 시간이 너무 길어지며, 반대로 너무 크면 발산하여 학습이 잘 이루어지지 않는다. 이것을 정하는 기술로 learning rate decay가 있다. 처음에는 크게 학습하다가 조금씩 작게 학습한다. 학습률을 서서히 낮추는 가장 간단한 방법은 매개변수 <strong>전체</strong>의 학습률 값을 일괄적으로 낮추는것이며 이를 발전시킨것이 AdaGrad이다.</p>

<p>$h \leftarrow h + \frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}$</p>

<p>$W \leftarrow W - \eta \frac{1}{\sqrt{h}} \frac{\partial L}{\partial W}$</p>

<p>여기서 $h$는 기존 기울기 값을 제곱하여 계속 더해준다. 그리고 매개변수를 갱신할 때 $\frac{1}{\sqrt{h}}$을 곱해 학습률을 조정해준다. 즉 매개변수의 원소 중에서 많이 움직인(크게 갱신된) 원소는 학습률이 낮아진다는 뜻이며, 학습률 감소가 매개변수의 원소마다 다르게 적용됨을 뜻한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="bp">None</span>
        
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
            
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
                
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="optimizer-compare">Optimizer Compare</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">dataset</span> <span class="kn">import</span> <span class="n">load_mnist</span>
<span class="kn">from</span> <span class="nn">optimizer</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">multi_layer_net</span> <span class="kn">import</span> <span class="n">MultiLayerNet</span>
<span class="kn">from</span> <span class="nn">util</span> <span class="kn">import</span> <span class="n">smooth_curve</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2000</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'SGD'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'Momentum'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Momentum</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'AdaGrad'</span><span class="p">]</span> <span class="o">=</span> <span class="n">AdaGrad</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'Adam'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">()</span>
<span class="n">optimizers</span><span class="p">[</span><span class="s">'RMSprop'</span><span class="p">]</span> <span class="o">=</span> <span class="n">RMSprop</span><span class="p">()</span>

<span class="n">networks</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">train_loss</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">MultiLayerNet</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span>
                                 <span class="n">hidden_size_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
                                 <span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">batch_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    <span class="n">t_batch</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="n">batch_mask</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">gradient</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">optimizers</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">update</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'====='</span> <span class="o">+</span> <span class="s">'epoch:'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">'====='</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">networks</span><span class="p">[</span><span class="n">key</span><span class="p">].</span><span class="n">loss</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">':'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=====epoch:0=====
SGD:2.323933561248506
Momentum:2.363245841817952
AdaGrad:2.0058678291110414
Adam:2.2334862629381247
RMSprop:14.22925630514287


=====epoch:100=====
SGD:1.5642248269340318
Momentum:0.38734450281445537
AdaGrad:0.17621693935291363
Adam:0.29530935596559615
RMSprop:0.27206693914231306


=====epoch:200=====
SGD:0.686122412862151
Momentum:0.15622272140572271
AdaGrad:0.06336690000897913
Adam:0.11336671915710754
RMSprop:0.17646344103478384


=====epoch:300=====
SGD:0.4545903408140268
Momentum:0.19771072117917854
AdaGrad:0.07949768723147957
Adam:0.09508616556545395
RMSprop:0.12008675039395529


=====epoch:400=====
SGD:0.4888092137718686
Momentum:0.16832245932781956
AdaGrad:0.08314873345194046
Adam:0.10753427697857422
RMSprop:0.16275149688659427


=====epoch:500=====
SGD:0.41182912871414307
Momentum:0.16891254992386134
AdaGrad:0.09577087646405533
Adam:0.13343288513695772
RMSprop:0.1509381717316755


=====epoch:600=====
SGD:0.38457191195719936
Momentum:0.17943574810854546
AdaGrad:0.0956186384355422
Adam:0.13159736035092054
RMSprop:0.21822940306148478


=====epoch:700=====
SGD:0.23862203822432784
Momentum:0.10301943877274536
AdaGrad:0.02559461765057868
Adam:0.06254043615993003
RMSprop:0.13542406013915123


=====epoch:800=====
SGD:0.29539795679444475
Momentum:0.16795679782037173
AdaGrad:0.06100571581620096
Adam:0.10210300999031789
RMSprop:0.12895927515125238


=====epoch:900=====
SGD:0.4140718396219327
Momentum:0.16519305717420346
AdaGrad:0.06692166063208266
Adam:0.07957113805987726
RMSprop:0.13062510151653964


=====epoch:1000=====
SGD:0.3515850025553312
Momentum:0.07630399868811209
AdaGrad:0.035831266442459486
Adam:0.031605081665158505
RMSprop:0.08687585855353055


=====epoch:1100=====
SGD:0.27671053746498353
Momentum:0.0927991189334633
AdaGrad:0.03429342415567612
Adam:0.06404277656831128
RMSprop:0.10490014031616401


=====epoch:1200=====
SGD:0.31741957526083986
Momentum:0.1123296449397075
AdaGrad:0.04982732116821773
Adam:0.062178961376442084
RMSprop:0.13679383222548375


=====epoch:1300=====
SGD:0.2292543596026353
Momentum:0.06967261211484445
AdaGrad:0.03302473628750588
Adam:0.05636652638864118
RMSprop:0.09318564993538125


=====epoch:1400=====
SGD:0.22237756148390314
Momentum:0.04882674904268745
AdaGrad:0.028742998382779012
Adam:0.015687868869984772
RMSprop:0.04109031955332386


=====epoch:1500=====
SGD:0.28039821371170026
Momentum:0.15725926811597074
AdaGrad:0.06663606677806189
Adam:0.07872465833141339
RMSprop:0.1811693993698395


=====epoch:1600=====
SGD:0.18627340858169092
Momentum:0.09531247495270898
AdaGrad:0.06224859468860602
Adam:0.036661451686031306
RMSprop:0.13888397442464653


=====epoch:1700=====
SGD:0.2345269210359547
Momentum:0.07508226021236863
AdaGrad:0.04970229707152042
Adam:0.07056549755653727
RMSprop:0.1535827013299852


=====epoch:1800=====
SGD:0.17507715717516453
Momentum:0.07569051309421965
AdaGrad:0.03774834237742847
Adam:0.026715994596425666
RMSprop:0.026451178822442755


=====epoch:1900=====
SGD:0.23511866141021298
Momentum:0.09448058945525774
AdaGrad:0.022293080750721103
Adam:0.02513916870501018
RMSprop:0.032113769609402695


=====epoch:2000=====
SGD:0.2229854127826571
Momentum:0.05897965953558401
AdaGrad:0.02959130337156857
Adam:0.03409000704065028
RMSprop:0.15438018030242323
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="s">'SGD'</span><span class="p">:</span> <span class="s">'o'</span><span class="p">,</span> <span class="s">'Momentum'</span><span class="p">:</span> <span class="s">'x'</span><span class="p">,</span> <span class="s">'AdaGrad'</span> <span class="p">:</span> <span class="s">'s'</span><span class="p">,</span> <span class="s">'Adam'</span><span class="p">:</span> <span class="s">'D'</span><span class="p">,</span><span class="s">'RMSprop'</span><span class="p">:</span><span class="s">'p'</span><span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">smooth_curve</span><span class="p">(</span><span class="n">train_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]),</span> <span class="n">marker</span><span class="o">=</span><span class="n">markers</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">key</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\assets\built\images\post_images\Scratch\optimization\output_19_0.png" alt="png" /></p>

<blockquote>
  <p>참고 : 사이토 고키, <strong>『</strong>DeepLearning from Scratch<strong>』</strong>, 한빛미디어(2020), p189-202</p>
</blockquote>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->

            <!--
            
            -->


            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/built/images/river.jpg" alt="ilvnax24er" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/ilvnax24er">ilvnax24er</a></h4>
                                
                                    <p>Read <a href="/author/ilvnax24er">more posts</a> by this author.</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/ilvnax24er">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/built/images/cover.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Archive &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/deeplearning/">Deeplearning</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Stochastic-Gradient-Descent">Deep Learning - Stochastic Gradient Descent</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Momentum">Deep Learning - Momentum</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/CNN(1)">Deep Learning from Scratch - CNN(1)</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/deeplearning/">
                                
                                    See all 17 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Training-Skills(1)">
                <div class="post-card-image" style="background-image: url(/assets/built/images/scratch-cover.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Training-Skills(1)">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Deeplearning</span>
                            
                        
                    

                    <h2 class="post-card-title">Deep Learning from Scratch - Training Skills(2)</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Weight Initialization

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/river.jpg" alt="ilvnax24er" />
                        
                        <span class="post-card-author">
                            <a href="/author/ilvnax24er/">ilvnax24er</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      5 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Back-Propagation(2)">
                <div class="post-card-image" style="background-image: url(/assets/built/images/scratch-cover.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Back-Propagation(2)">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Deeplearning</span>
                            
                        
                    

                    <h2 class="post-card-title">Deep Learning from Scratch - Back Propagation (2)</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Affine/Softmax Layer

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/river.jpg" alt="ilvnax24er" />
                        
                        <span class="post-card-author">
                            <a href="/author/ilvnax24er/">ilvnax24er</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      3 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://ilvnax24er.github.io/">
            
            <span>Archive</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Deep Learning from Scratch - Training Skills(1)</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Deep+Learning+from+Scratch+-+Training+Skills%281%29&amp;url=https://ilvnax24er.github.io/Optimization"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://ilvnax24er.github.io/Optimization"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://ilvnax24er.github.io/">Archive</a> &copy; 2021</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- syntax.css 추가 -->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- web font 추가 -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css">

    <!-- custom css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/custom.css" />

    <!-- font awesome -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-xxxxxxxx-x', 'auto');
  ga('send', 'pageview');

 </script>



    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
